STRIMZI_BROKER_ID=0
Starting Kafka with configuration:
##############################
##############################
# This file is automatically generated by the Strimzi Cluster Operator
# Any changes to this file will be ignored and overwritten!
##############################
##############################

##########
# Node ID
##########
node.id=0

##########
# KRaft configuration
##########
process.roles=broker,controller
controller.listener.names=CONTROLPLANE-9090
controller.quorum.voters=0@my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090

##########
# KRaft metadata log dir configuration
##########
metadata.log.dir=/var/lib/kafka/data-0/kafka-log0

##########
# Kafka message logs configuration
##########
log.dirs=/var/lib/kafka/data-0/kafka-log0

##########
# Control Plane listener
##########
listener.name.controlplane-9090.ssl.keystore.certificate.chain=${strimzisecrets:ksql0491/my-cluster-dual-role-0:my-cluster-dual-role-0.crt}
listener.name.controlplane-9090.ssl.keystore.key=${strimzisecrets:ksql0491/my-cluster-dual-role-0:my-cluster-dual-role-0.key}
listener.name.controlplane-9090.ssl.keystore.type=PEM
listener.name.controlplane-9090.ssl.truststore.certificates=${strimzisecrets:ksql0491/my-cluster-cluster-ca-cert:*.crt}
listener.name.controlplane-9090.ssl.truststore.type=PEM
listener.name.controlplane-9090.ssl.client.auth=required

##########
# Replication listener
##########
listener.name.replication-9091.ssl.keystore.certificate.chain=${strimzisecrets:ksql0491/my-cluster-dual-role-0:my-cluster-dual-role-0.crt}
listener.name.replication-9091.ssl.keystore.key=${strimzisecrets:ksql0491/my-cluster-dual-role-0:my-cluster-dual-role-0.key}
listener.name.replication-9091.ssl.keystore.type=PEM
listener.name.replication-9091.ssl.truststore.certificates=${strimzisecrets:ksql0491/my-cluster-cluster-ca-cert:*.crt}
listener.name.replication-9091.ssl.truststore.type=PEM
listener.name.replication-9091.ssl.client.auth=required

##########
# Listener configuration: PLAIN-9092
##########

##########
# Listener configuration: TLS-9093
##########
listener.name.tls-9093.ssl.keystore.certificate.chain=${strimzisecrets:ksql0491/my-cluster-dual-role-0:my-cluster-dual-role-0.crt}
listener.name.tls-9093.ssl.keystore.key=${strimzisecrets:ksql0491/my-cluster-dual-role-0:my-cluster-dual-role-0.key}
listener.name.tls-9093.ssl.keystore.type=PEM


##########
# Common listener configuration
##########
listener.security.protocol.map=CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL
listeners=CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093
inter.broker.listener.name=REPLICATION-9091
advertised.listeners=CONTROLPLANE-9090://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9090,REPLICATION-9091://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9091,PLAIN-9092://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9092,TLS-9093://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9093
sasl.enabled.mechanisms=
ssl.endpoint.identification.algorithm=HTTPS

##########
# Config providers
##########
# Configuration providers configured by the user and by Strimzi
config.providers=strimzienv,strimzisecrets,strimzifile,strimzidir
config.providers.strimzienv.class=org.apache.kafka.common.config.provider.EnvVarConfigProvider
config.providers.strimzienv.param.allowlist.pattern=.*
config.providers.strimzisecrets.class=io.strimzi.kafka.KubernetesSecretConfigProvider
config.providers.strimzifile.class=org.apache.kafka.common.config.provider.FileConfigProvider
config.providers.strimzifile.param.allowed.paths=/opt/kafka
config.providers.strimzidir.class=org.apache.kafka.common.config.provider.DirectoryConfigProvider
config.providers.strimzidir.param.allowed.paths=/opt/kafka

##########
# User provided configuration
##########
min.insync.replicas=1
default.replication.factor=1
offsets.topic.replication.factor=1
transaction.state.log.min.isr=1
transaction.state.log.replication.factor=1
Making sure the Kraft storage is formatted with cluster ID V_zcuHrFSXW7kfZU7SI0dg and metadata version 4.1-IV1
2026-02-12 18:31:54 INFO  [main] Log4jControllerRegistration$:33 - Registered `kafka:type=kafka.Log4jController` MBean
2026-02-12 18:31:54 INFO  [main] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:31:55 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-cluster-ca-cert in namespace ksql0491
2026-02-12 18:31:55 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-dual-role-0 in namespace ksql0491
2026-02-12 18:31:55 INFO  [main] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:31:55 INFO  [main] AbstractConfig:380 - KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = CONTROLPLANE-9090://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9090,REPLICATION-9091://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9091,PLAIN-9092://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9092,TLS-9093://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLPLANE-9090
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.regex.refresh.interval.ms = 600000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.rebalance.protocols = [classic, consumer, streams]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.assignors = [simple]
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.share.sessions = 2000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 2000
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	group.streams.heartbeat.interval.ms = 5000
	group.streams.max.heartbeat.interval.ms = 15000
	group.streams.max.session.timeout.ms = 60000
	group.streams.max.size = 2147483647
	group.streams.max.standby.replicas = 2
	group.streams.min.heartbeat.interval.ms = 5000
	group.streams.min.session.timeout.ms = 45000
	group.streams.num.standby.replicas = 0
	group.streams.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = REPLICATION-9091
	internal.metadata.delete.delay.millis = 60000
	internal.metadata.log.segment.bytes = null
	internal.metadata.max.batch.size.in.bytes = 8388608
	internal.metadata.max.fetch.size.in.bytes = 8388608
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL
	listeners = CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data-0/kafka-log0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = /var/lib/kafka/data-0/kafka-log0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = []
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.cold.partition.snapshot.interval.ms = 300000
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = HTTPS
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transaction.two.phase.commit.enable = false
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false

Formatting metadata directory /var/lib/kafka/data-0/kafka-log0 with metadata.version 4.1-IV1.
KRaft storage formatting is done

Preparing Kafka Agent configuration

+ exec /usr/bin/tini -w -e 143 -- /opt/kafka/bin/kafka-server-start.sh /tmp/strimzi.properties
2026-02-12 18:31:57 INFO  [main] KafkaAgent:345 - Starting KafkaAgent with sslTrustStoreSecretName=my-cluster-cluster-ca-cert sslKeyStoreSecretName=my-cluster-dual-role-0 namespace=ksql0491
2026-02-12 18:31:59 INFO  [main] Server:555 - jetty-12.0.22; built: 2025-06-02T15:25:31.946Z; git: 335c9ab44a5591f0ea941bf350e139b8c4f5537c; jvm 17.0.17+10-LTS
2026-02-12 18:31:59 INFO  [main] ContextHandler:764 - Started oejsh.ContextHandler@4d157787{/v1/broker-state,/v1/broker-state,b=null,a=AVAILABLE,h=iska.KafkaAgent$@68ed96ca{STARTED}}
2026-02-12 18:31:59 INFO  [main] ContextHandler:764 - Started oejsh.ContextHandler@6d1310f6{/v1/ready,/v1/ready,b=null,a=AVAILABLE,h=iska.KafkaAgent$@3228d990{STARTED}}
2026-02-12 18:31:59 INFO  [main] SslContextFactory:337 - x509=X509@2fa7ae9(my-cluster-dual-role-0,h=[my-cluster-kafka-bootstrap.ksql0491.svc, my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc, my-cluster-kafka-bootstrap.ksql0491, my-cluster-kafka-bootstrap.ksql0491.svc.cluster.local, my-cluster-kafka-bootstrap, my-cluster-kafka-brokers.ksql0491.svc, my-cluster-kafka-brokers.ksql0491, my-cluster-kafka-brokers, my-cluster-kafka-brokers.ksql0491.svc.cluster.local, my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local, my-cluster-kafka],a=[],w=[]) for Server@7577b641[provider=null,keyStore=null,trustStore=null]
2026-02-12 18:31:59 INFO  [main] AbstractConnector:326 - Started ServerConnector@4310fc58{SSL, (ssl, http/1.1)}{0.0.0.0:8443}
2026-02-12 18:31:59 INFO  [main] AbstractConnector:326 - Started ServerConnector@652b9bfd{HTTP/1.1, (http/1.1)}{localhost:8080}
2026-02-12 18:31:59 INFO  [main] Server:612 - Started oejs.Server@344561e0{STARTING}[12.0.22,sto=30000] @2732ms
2026-02-12 18:31:59 INFO  [main] KafkaAgent:129 - Starting metrics registry
2026-02-12 18:31:59 INFO  [main] KafkaAgent:165 - Found class org.apache.kafka.server.metrics.KafkaYammerMetrics for Kafka 3.3 and newer.
2026-02-12 18:31:59 INFO  [main] Log4jControllerRegistration$:33 - Registered `kafka:type=kafka.Log4jController` MBean
2026-02-12 18:31:59 INFO  [main] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:31:59 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-cluster-ca-cert in namespace ksql0491
2026-02-12 18:31:59 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-dual-role-0 in namespace ksql0491
2026-02-12 18:31:59 INFO  [main] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-cluster-ca-cert in namespace ksql0491
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-dual-role-0 in namespace ksql0491
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-cluster-ca-cert in namespace ksql0491
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-dual-role-0 in namespace ksql0491
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:00 INFO  [main] LoggingSignalHandler:72 - Registered signal handlers for TERM, INT, HUP
2026-02-12 18:32:00 INFO  [main] ControllerServer:69 - [ControllerServer id=0] Starting controller
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-cluster-ca-cert in namespace ksql0491
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-dual-role-0 in namespace ksql0491
2026-02-12 18:32:00 INFO  [main] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:00 INFO  [main] ConnectionQuotas:69 - Updated connection-accept-rate max connection creation rate to 2147483647
2026-02-12 18:32:01 INFO  [main] SocketServer:69 - [SocketServer listenerType=CONTROLLER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLPLANE-9090)
2026-02-12 18:32:01 INFO  [main] EndpointReadyFutures:168 - authorizerStart completed for endpoint CONTROLPLANE-9090. Endpoint is now READY.
2026-02-12 18:32:01 INFO  [main] SharedServer:69 - [SharedServer id=0] Starting SharedServer
2026-02-12 18:32:01 INFO  [main] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:32:01 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-cluster-ca-cert in namespace ksql0491
2026-02-12 18:32:01 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-dual-role-0 in namespace ksql0491
2026-02-12 18:32:01 INFO  [main] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:01 INFO  [main] UnifiedLog:2449 - [LogLoader partition=__cluster_metadata-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:32:01 INFO  [main] UnifiedLog:2471 - [LogLoader partition=__cluster_metadata-0, dir=/var/lib/kafka/data-0/kafka-log0] Reloading from producer snapshot and rebuilding producer state from offset 0
2026-02-12 18:32:01 INFO  [main] UnifiedLog:2507 - [LogLoader partition=__cluster_metadata-0, dir=/var/lib/kafka/data-0/kafka-log0] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0
2026-02-12 18:32:01 INFO  [main] KafkaMetadataLog$:580 - Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data-0/kafka-log0/__cluster_metadata-0
2026-02-12 18:32:01 INFO  [raft-expiration-reaper] TimingWheelExpirationService$ExpiredOperationReaper:133 - [raft-expiration-reaper]: Starting
2026-02-12 18:32:01 INFO  [main] KafkaRaftClient:503 - [RaftManager id=0] Reading KRaft snapshot and log as part of the initialization
2026-02-12 18:32:01 INFO  [main] KafkaRaftClient:505 - [RaftManager id=0] Starting voters are VoterSet(voters={0=VoterNode(voterKey=ReplicaKey(id=0, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLPLANE-9090)=my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local/10.128.2.25:9090}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])})
2026-02-12 18:32:01 INFO  [main] KafkaRaftClient:531 - [RaftManager id=0] Starting request manager with static voters: [my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)]
2026-02-12 18:32:01 INFO  [main] QuorumState:732 - [RaftManager id=0] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1211, highWatermark=Optional.empty) from null
2026-02-12 18:32:01 INFO  [main] QuorumState:749 - [RaftManager id=0] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1211, highWatermark=Optional.empty) from null
2026-02-12 18:32:01 INFO  [main] QuorumState:749 - [RaftManager id=0] Completed transition to ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1847, highWatermark=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[0], electionTimeoutMs=1211, highWatermark=Optional.empty)
2026-02-12 18:32:01 INFO  [main] QuorumState:732 - [RaftManager id=0] Attempting durable transition to CandidateState(localId=0, localDirectoryId=WcnePDcdf5I1t1eNvMsYvA, epoch=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1095) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1847, highWatermark=Optional.empty)
2026-02-12 18:32:01 INFO  [main] QuorumState:749 - [RaftManager id=0] Completed transition to CandidateState(localId=0, localDirectoryId=WcnePDcdf5I1t1eNvMsYvA, epoch=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1095) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1847, highWatermark=Optional.empty)
2026-02-12 18:32:01 INFO  [main] QuorumState:732 - [RaftManager id=0] Attempting durable transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=0, directoryId=WcnePDcdf5I1t1eNvMsYvA), listeners=Endpoints(endpoints={ListenerName(CONTROLPLANE-9090)=my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc/<unresolved>:9090}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={0=ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=0, localDirectoryId=WcnePDcdf5I1t1eNvMsYvA, epoch=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1095)
2026-02-12 18:32:01 INFO  [main] QuorumState:749 - [RaftManager id=0] Completed transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=0, directoryId=WcnePDcdf5I1t1eNvMsYvA), listeners=Endpoints(endpoints={ListenerName(CONTROLPLANE-9090)=my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc/<unresolved>:9090}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={0=ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=0, localDirectoryId=WcnePDcdf5I1t1eNvMsYvA, epoch=1, epochElection=EpochElection(voterStates={0=VoterState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1095)
2026-02-12 18:32:01 INFO  [kafka-0-raft-outbound-request-thread] KafkaNetworkChannel$SendThread:133 - [kafka-0-raft-outbound-request-thread]: Starting
2026-02-12 18:32:01 INFO  [kafka-0-raft-io-thread] KafkaRaftClientDriver:133 - [kafka-0-raft-io-thread]: Starting
2026-02-12 18:32:01 INFO  [main] ControllerServer:57 - [ControllerServer id=0] Waiting for controller quorum voters future
2026-02-12 18:32:01 INFO  [main] ControllerServer:60 - [ControllerServer id=0] Finished waiting for controller quorum voters future
2026-02-12 18:32:01 INFO  [kafka-0-raft-io-thread] LeaderState:780 - [RaftManager id=0] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=0, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)]
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:238 - [MetadataLoader id=0] initializeNewPublishers: The loader is still catching up because we have loaded up to offset -1, but the high water mark is 1
2026-02-12 18:32:01 INFO  [kafka-0-raft-io-thread] KafkaRaftClient:3430 - [RaftManager id=0] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1375964885
2026-02-12 18:32:01 INFO  [kafka-0-raft-io-thread] KafkaRaftClient:416 - [RaftManager id=0] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@1375964885 to 0 since there are no snapshots
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:243 - [MetadataLoader id=0] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1
2026-02-12 18:32:01 INFO  [main] PeriodicTaskControlManager:167 - [QuorumController id=0] Registering periodic task writeNoOpRecord to run every 500 ms
2026-02-12 18:32:01 INFO  [main] PeriodicTaskControlManager:167 - [QuorumController id=0] Registering periodic task maybeFenceStaleBroker to run every 1125 ms
2026-02-12 18:32:01 INFO  [main] PeriodicTaskControlManager:167 - [QuorumController id=0] Registering periodic task electPreferred to run every 300000 ms
2026-02-12 18:32:01 INFO  [main] PeriodicTaskControlManager:167 - [QuorumController id=0] Registering periodic task electUnclean to run every 300000 ms
2026-02-12 18:32:01 INFO  [main] PeriodicTaskControlManager:167 - [QuorumController id=0] Registering periodic task expireDelegationTokens to run every 3600000 ms
2026-02-12 18:32:01 INFO  [main] PeriodicTaskControlManager:167 - [QuorumController id=0] Registering periodic task generatePeriodicPerformanceMessage to run every 60000 ms
2026-02-12 18:32:01 INFO  [main] QuorumController:1603 - [QuorumController id=0] Creating new QuorumController with clusterId V_zcuHrFSXW7kfZU7SI0dg
2026-02-12 18:32:01 INFO  [kafka-0-raft-io-thread] KafkaRaftClient:3430 - [RaftManager id=0] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@993440987
2026-02-12 18:32:01 INFO  [kafka-0-raft-io-thread] KafkaRaftClient:416 - [RaftManager id=0] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@993440987 to 0 since there are no snapshots
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] QuorumController:1078 - [QuorumController id=0] Becoming the active controller at epoch 1, next write offset 1.
2026-02-12 18:32:01 WARN  [quorum-controller-0-event-handler] QuorumController:106 - [QuorumController id=0] Performing controller activation. The metadata log appears to be empty. Appending 4 bootstrap record(s) in metadata transaction at metadata.version 4.1-IV1 from bootstrap source 'the binary bootstrap metadata file: /var/lib/kafka/data-0/kafka-log0/bootstrap.checkpoint'.
2026-02-12 18:32:01 INFO  [controller-0-ThrottledChannelReaper-Fetch] ClientQuotaManager$ThrottledChannelReaper:133 - [controller-0-ThrottledChannelReaper-Fetch]: Starting
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] OffsetControlManager:392 - [QuorumController id=0] Replayed BeginTransactionRecord(name='Bootstrap records') at offset 1.
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] FeatureControlManager:449 - [QuorumController id=0] Replayed a FeatureLevelRecord setting metadata.version to 4.1-IV1
2026-02-12 18:32:01 INFO  [controller-0-ThrottledChannelReaper-Produce] ClientQuotaManager$ThrottledChannelReaper:133 - [controller-0-ThrottledChannelReaper-Produce]: Starting
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] FeatureControlManager:460 - [QuorumController id=0] Replayed a FeatureLevelRecord setting feature eligible.leader.replicas.version to 1
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] FeatureControlManager:460 - [QuorumController id=0] Replayed a FeatureLevelRecord setting feature group.version to 1
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] FeatureControlManager:460 - [QuorumController id=0] Replayed a FeatureLevelRecord setting feature transaction.version to 2
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=BROKER, name='') which set configuration min.insync.replicas to 1
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] OffsetControlManager:404 - [QuorumController id=0] Replayed EndTransactionRecord() at offset 7.
2026-02-12 18:32:01 INFO  [controller-0-ThrottledChannelReaper-Request] ClientQuotaManager$ThrottledChannelReaper:133 - [controller-0-ThrottledChannelReaper-Request]: Starting
2026-02-12 18:32:01 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:231 - [QuorumController id=0] Activated periodic tasks: electPreferred, electUnclean, expireDelegationTokens, generatePeriodicPerformanceMessage, maybeFenceStaleBroker, writeNoOpRecord
2026-02-12 18:32:01 INFO  [controller-0-ThrottledChannelReaper-ControllerMutation] ClientQuotaManager$ThrottledChannelReaper:133 - [controller-0-ThrottledChannelReaper-ControllerMutation]: Starting
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:243 - [MetadataLoader id=0] initializeNewPublishers: The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:247 - [MetadataLoader id=0] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 8
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 7
2026-02-12 18:32:01 INFO  [ExpirationReaper-0-AlterAcls] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-AlterAcls]: Starting
2026-02-12 18:32:01 INFO  [main] ControllerServer:57 - [ControllerServer id=0] Waiting for the controller metadata publishers to be installed
2026-02-12 18:32:01 INFO  [main] ControllerServer:60 - [ControllerServer id=0] Finished waiting for the controller metadata publishers to be installed
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 7
2026-02-12 18:32:01 INFO  [main] SocketServer:69 - [SocketServer listenerType=CONTROLLER, nodeId=0] Enabling request processing.
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 7
2026-02-12 18:32:01 INFO  [main] DataPlaneAcceptor:69 - Awaiting socket connections on 0.0.0.0:9090.
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] FeaturesPublisher:63 - [ControllerServer id=0] Loaded new metadata FinalizedFeatures[metadataVersion=4.1-IV1, finalizedFeatures={group.version=1, transaction.version=2, eligible.leader.replicas.version=1, metadata.version=27}, finalizedFeaturesEpoch=7].
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 7
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 7
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=0 with a snapshot at offset 7
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:69 - [DynamicConfigPublisher controller id=0] Updating cluster configuration : min.insync.replicas -> 1
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:32:01 INFO  [main] ControllerServer:57 - [ControllerServer id=0] Waiting for all of the authorizer futures to be completed
2026-02-12 18:32:01 INFO  [main] ControllerServer:60 - [ControllerServer id=0] Finished waiting for all of the authorizer futures to be completed
2026-02-12 18:32:01 INFO  [main] ControllerServer:57 - [ControllerServer id=0] Waiting for all of the SocketServer Acceptors to be started
2026-02-12 18:32:01 INFO  [main] ControllerServer:60 - [ControllerServer id=0] Finished waiting for all of the SocketServer Acceptors to be started
2026-02-12 18:32:01 INFO  [main] BrokerServer:69 - [BrokerServer id=0] Transition from SHUTDOWN to STARTING
2026-02-12 18:32:01 INFO  [controller-0-registration-manager-event-handler] ControllerRegistrationManager:69 - [ControllerRegistrationManager id=0 incarnation=ujKcXZ6AR4GdX6adIKtd_g] initialized channel manager.
2026-02-12 18:32:01 INFO  [controller-0-to-controller-registration-channel-manager] NodeToControllerRequestThread:133 - [controller-0-to-controller-registration-channel-manager]: Starting
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:01 INFO  [kafka-0-metadata-loader-event-handler] AbstractConfig:380 - KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = CONTROLPLANE-9090://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9090,REPLICATION-9091://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9091,PLAIN-9092://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9092,TLS-9093://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLPLANE-9090
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.regex.refresh.interval.ms = 600000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.rebalance.protocols = [classic, consumer, streams]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.assignors = [simple]
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.share.sessions = 2000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 2000
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	group.streams.heartbeat.interval.ms = 5000
	group.streams.max.heartbeat.interval.ms = 15000
	group.streams.max.session.timeout.ms = 60000
	group.streams.max.size = 2147483647
	group.streams.max.standby.replicas = 2
	group.streams.min.heartbeat.interval.ms = 5000
	group.streams.min.session.timeout.ms = 45000
	group.streams.num.standby.replicas = 0
	group.streams.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = REPLICATION-9091
	internal.metadata.delete.delay.millis = 60000
	internal.metadata.log.segment.bytes = null
	internal.metadata.max.batch.size.in.bytes = 8388608
	internal.metadata.max.fetch.size.in.bytes = 8388608
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL
	listeners = CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data-0/kafka-log0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = /var/lib/kafka/data-0/kafka-log0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = []
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.cold.partition.snapshot.interval.ms = 300000
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = HTTPS
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transaction.two.phase.commit.enable = false
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false

2026-02-12 18:32:01 INFO  [controller-0-to-controller-registration-channel-manager] NodeToControllerRequestThread:69 - [controller-0-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2026-02-12 18:32:01 INFO  [main] BrokerServer:69 - [BrokerServer id=0] Starting broker
2026-02-12 18:32:01 INFO  [main] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:32:02 INFO  [controller-0-registration-manager-event-handler] ControllerRegistrationManager:69 - [ControllerRegistrationManager id=0 incarnation=ujKcXZ6AR4GdX6adIKtd_g] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=0, incarnationId=ujKcXZ6AR4GdX6adIKtd_g, zkMigrationReady=false, listeners=[Listener(name='CONTROLPLANE-9090', host='my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc', port=9090, securityProtocol=1)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=27), Feature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1)])
2026-02-12 18:32:02 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-cluster-ca-cert in namespace ksql0491
2026-02-12 18:32:02 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=0 with a snapshot at offset 7
2026-02-12 18:32:02 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing DynamicTopicClusterQuotaPublisher controller id=0 with a snapshot at offset 7
2026-02-12 18:32:02 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing ScramPublisher controller id=0 with a snapshot at offset 7
2026-02-12 18:32:02 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=0 with a snapshot at offset 7
2026-02-12 18:32:02 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 7
2026-02-12 18:32:02 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing AclPublisher controller id=0 with a snapshot at offset 7
2026-02-12 18:32:02 INFO  [main] AbstractKubernetesConfigProvider:123 - Retrieving configuration from Secret my-cluster-dual-role-0 in namespace ksql0491
2026-02-12 18:32:02 INFO  [main] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:02 INFO  [broker-0-ThrottledChannelReaper-Fetch] ClientQuotaManager$ThrottledChannelReaper:133 - [broker-0-ThrottledChannelReaper-Fetch]: Starting
2026-02-12 18:32:02 INFO  [broker-0-ThrottledChannelReaper-Produce] ClientQuotaManager$ThrottledChannelReaper:133 - [broker-0-ThrottledChannelReaper-Produce]: Starting
2026-02-12 18:32:02 INFO  [broker-0-ThrottledChannelReaper-Request] ClientQuotaManager$ThrottledChannelReaper:133 - [broker-0-ThrottledChannelReaper-Request]: Starting
2026-02-12 18:32:02 INFO  [broker-0-ThrottledChannelReaper-ControllerMutation] ClientQuotaManager$ThrottledChannelReaper:133 - [broker-0-ThrottledChannelReaper-ControllerMutation]: Starting
2026-02-12 18:32:02 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for controller quorum voters future
2026-02-12 18:32:02 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for controller quorum voters future
2026-02-12 18:32:02 INFO  [broker-0-to-controller-forwarding-channel-manager] NodeToControllerRequestThread:133 - [broker-0-to-controller-forwarding-channel-manager]: Starting
2026-02-12 18:32:02 INFO  [broker-0-to-controller-forwarding-channel-manager] NodeToControllerRequestThread:69 - [broker-0-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2026-02-12 18:32:02 INFO  [quorum-controller-0-event-handler] ClusterControlManager:694 - [QuorumController id=0] Replayed RegisterControllerRecord containing ControllerRegistration(id=0, incarnationId=ujKcXZ6AR4GdX6adIKtd_g, zkMigrationReady=false, listeners=[Endpoint(listenerName='CONTROLPLANE-9090', securityProtocol=SSL, host='my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc', port=9090)], supportedFeatures={eligible.leader.replicas.version: 0-1, group.version: 0-1, kraft.version: 0-1, metadata.version: 7-27, share.version: 0-1, transaction.version: 0-2}).
2026-02-12 18:32:02 INFO  [client-metrics-reaper] SystemTimerReaper$Reaper:133 - [client-metrics-reaper]: Starting
2026-02-12 18:32:02 INFO  [controller-0-registration-manager-event-handler] ControllerRegistrationManager:69 - [ControllerRegistrationManager id=0 incarnation=ujKcXZ6AR4GdX6adIKtd_g] Our registration has been persisted to the metadata log.
2026-02-12 18:32:02 INFO  [controller-0-to-controller-registration-channel-manager] ControllerRegistrationManager:69 - [ControllerRegistrationManager id=0 incarnation=ujKcXZ6AR4GdX6adIKtd_g] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest.
2026-02-12 18:32:02 INFO  [main] ConnectionQuotas:69 - Updated connection-accept-rate max connection creation rate to 2147483647
2026-02-12 18:32:02 INFO  [main] SocketServer:69 - [SocketServer listenerType=BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(REPLICATION-9091)
2026-02-12 18:32:02 INFO  [main] ConnectionQuotas:69 - Updated connection-accept-rate max connection creation rate to 2147483647
2026-02-12 18:32:02 INFO  [main] SocketServer:69 - [SocketServer listenerType=BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAIN-9092)
2026-02-12 18:32:02 INFO  [main] ConnectionQuotas:69 - Updated connection-accept-rate max connection creation rate to 2147483647
2026-02-12 18:32:03 INFO  [main] SocketServer:69 - [SocketServer listenerType=BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(TLS-9093)
2026-02-12 18:32:03 INFO  [broker-0-to-controller-alter-partition-channel-manager] NodeToControllerRequestThread:133 - [broker-0-to-controller-alter-partition-channel-manager]: Starting
2026-02-12 18:32:03 INFO  [broker-0-to-controller-alter-partition-channel-manager] NodeToControllerRequestThread:69 - [broker-0-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2026-02-12 18:32:03 INFO  [broker-0-to-controller-directory-assignments-channel-manager] NodeToControllerRequestThread:133 - [broker-0-to-controller-directory-assignments-channel-manager]: Starting
2026-02-12 18:32:03 INFO  [broker-0-to-controller-directory-assignments-channel-manager] NodeToControllerRequestThread:69 - [broker-0-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2026-02-12 18:32:03 INFO  [ExpirationReaper-0-Produce] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-Produce]: Starting
2026-02-12 18:32:03 INFO  [ExpirationReaper-0-Fetch] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-Fetch]: Starting
2026-02-12 18:32:03 INFO  [ExpirationReaper-0-DeleteRecords] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-DeleteRecords]: Starting
2026-02-12 18:32:03 INFO  [ExpirationReaper-0-RemoteFetch] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-RemoteFetch]: Starting
2026-02-12 18:32:03 INFO  [ExpirationReaper-0-RemoteListOffsets] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-RemoteListOffsets]: Starting
2026-02-12 18:32:03 INFO  [ExpirationReaper-0-ShareFetch] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-ShareFetch]: Starting
2026-02-12 18:32:03 INFO  [share-coordinator-reaper] SystemTimerReaper$Reaper:133 - [share-coordinator-reaper]: Starting
2026-02-12 18:32:03 INFO  [share-coordinator-event-processor-0] MultiThreadedEventProcessor$EventProcessorThread:176 - [share-coordinator-event-processor-0]: Starting
2026-02-12 18:32:03 INFO  [persister-state-manager-reaper] SystemTimerReaper$Reaper:133 - [persister-state-manager-reaper]: Starting
2026-02-12 18:32:03 INFO  [PersisterStateManager] PersisterStateManager$SendThread:133 - [PersisterStateManager]: Starting
2026-02-12 18:32:03 INFO  [group-coordinator-reaper] SystemTimerReaper$Reaper:133 - [group-coordinator-reaper]: Starting
2026-02-12 18:32:03 INFO  [group-coordinator-event-processor-0] MultiThreadedEventProcessor$EventProcessorThread:176 - [group-coordinator-event-processor-0]: Starting
2026-02-12 18:32:03 INFO  [group-coordinator-event-processor-1] MultiThreadedEventProcessor$EventProcessorThread:176 - [group-coordinator-event-processor-1]: Starting
2026-02-12 18:32:03 INFO  [group-coordinator-event-processor-2] MultiThreadedEventProcessor$EventProcessorThread:176 - [group-coordinator-event-processor-2]: Starting
2026-02-12 18:32:03 INFO  [group-coordinator-event-processor-3] MultiThreadedEventProcessor$EventProcessorThread:176 - [group-coordinator-event-processor-3]: Starting
2026-02-12 18:32:03 INFO  [main] LogManager:69 - Unable to read the broker epoch in /var/lib/kafka/data-0/kafka-log0.
2026-02-12 18:32:03 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:69 - [BrokerLifecycleManager id=0] Incarnation ivpYGGckRly2x806M5oopw of broker 0 in cluster V_zcuHrFSXW7kfZU7SI0dg is now STARTING.
2026-02-12 18:32:03 INFO  [broker-0-to-controller-heartbeat-channel-manager] NodeToControllerRequestThread:133 - [broker-0-to-controller-heartbeat-channel-manager]: Starting
2026-02-12 18:32:03 INFO  [broker-0-to-controller-heartbeat-channel-manager] NodeToControllerRequestThread:69 - [broker-0-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090 (id: 0 rack: null isFenced: false)
2026-02-12 18:32:03 INFO  [share-group-lock-timeout-reaper] SystemTimerReaper$Reaper:133 - [share-group-lock-timeout-reaper]: Starting
2026-02-12 18:32:03 INFO  [ExpirationReaper-0-AlterAcls] DelayedOperationPurgatory$ExpiredOperationReaper:133 - [ExpirationReaper-0-AlterAcls]: Starting
2026-02-12 18:32:03 INFO  [quorum-controller-0-event-handler] ClusterControlManager:439 - [QuorumController id=0] No previous registration found for broker 0. New incarnation ID is ivpYGGckRly2x806M5oopw.  Generated 0 record(s) to clean up previous incarnations. New broker epoch is 13.
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing MetadataVersionPublisher(id=0) with a snapshot at offset 12
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 12
2026-02-12 18:32:03 INFO  [quorum-controller-0-event-handler] ClusterControlManager:581 - [QuorumController id=0] Replayed initial RegisterBrokerRecord for broker 0: RegisterBrokerRecord(brokerId=0, isMigratingZkBroker=false, incarnationId=ivpYGGckRly2x806M5oopw, brokerEpoch=13, endPoints=[BrokerEndpoint(name='REPLICATION-9091', host='my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc', port=9091, securityProtocol=1), BrokerEndpoint(name='PLAIN-9092', host='my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc', port=9092, securityProtocol=0), BrokerEndpoint(name='TLS-9093', host='my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc', port=9093, securityProtocol=1)], features=[BrokerFeature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=27), BrokerFeature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), BrokerFeature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1)], rack=null, fenced=true, inControlledShutdown=false, logDirs=[WcnePDcdf5I1t1eNvMsYvA])
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] BrokerMetadataPublisher:69 - [BrokerMetadataPublisher id=0] Publishing initial metadata at offset OffsetAndEpoch[offset=12, epoch=1] with metadata.version Optional[4.1-IV1].
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Loading logs from log dirs ArrayBuffer(/var/lib/kafka/data-0/kafka-log0)
2026-02-12 18:32:03 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:69 - [BrokerLifecycleManager id=0] Successfully registered broker 0 with broker epoch 13
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - No logs found to be loaded in /var/lib/kafka/data-0/kafka-log0
2026-02-12 18:32:03 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for the broker metadata publishers to be installed
2026-02-12 18:32:03 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for the broker metadata publishers to be installed
2026-02-12 18:32:03 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for the controller to acknowledge that we are caught up
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Loaded 0 logs in 55ms
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Starting log cleanup with a period of 300000 ms.
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Starting log flusher with a default period of 9223372036854775807 ms.
2026-02-12 18:32:03 INFO  [kafka-0-metadata-loader-event-handler] LogCleaner:206 - Starting the log cleaner
2026-02-12 18:32:04 INFO  [kafka-log-cleaner-thread-0] LogCleaner$CleanerThread:133 - [kafka-log-cleaner-thread-0]: Starting
2026-02-12 18:32:04 INFO  [AddPartitionsToTxnSenderThread-0] AddPartitionsToTxnManager:133 - [AddPartitionsToTxnSenderThread-0]: Starting
2026-02-12 18:32:04 INFO  [LogDirFailureHandler] ReplicaManager$LogDirFailureHandler:133 - [LogDirFailureHandler]: Starting
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] GroupCoordinatorService:2252 - [GroupCoordinator id=0] Starting up.
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] GroupCoordinatorService:2255 - [GroupCoordinator id=0] Startup complete.
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] TransactionCoordinator:69 - [TransactionCoordinator id=0] Starting up.
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] TransactionCoordinator:69 - [TransactionCoordinator id=0] Startup complete.
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] ShareCoordinatorService:283 - [ShareCoordinator id=0] Starting up.
2026-02-12 18:32:04 INFO  [TxnMarkerSenderThread-0] TransactionMarkerChannelManager:133 - [TxnMarkerSenderThread-0]: Starting
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] ShareCoordinatorService:285 - [ShareCoordinator id=0] Startup complete.
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:69 - [DynamicConfigPublisher broker id=0] Updating cluster configuration : min.insync.replicas -> 1
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] AbstractConfig:380 - KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = CONTROLPLANE-9090://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9090,REPLICATION-9091://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9091,PLAIN-9092://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9092,TLS-9093://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLPLANE-9090
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.regex.refresh.interval.ms = 600000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.rebalance.protocols = [classic, consumer, streams]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.assignors = [simple]
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.share.sessions = 2000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 2000
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	group.streams.heartbeat.interval.ms = 5000
	group.streams.max.heartbeat.interval.ms = 15000
	group.streams.max.session.timeout.ms = 60000
	group.streams.max.size = 2147483647
	group.streams.max.standby.replicas = 2
	group.streams.min.heartbeat.interval.ms = 5000
	group.streams.min.session.timeout.ms = 45000
	group.streams.num.standby.replicas = 0
	group.streams.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = REPLICATION-9091
	internal.metadata.delete.delay.millis = 60000
	internal.metadata.log.segment.bytes = null
	internal.metadata.max.batch.size.in.bytes = 8388608
	internal.metadata.max.fetch.size.in.bytes = 8388608
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL
	listeners = CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data-0/kafka-log0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = /var/lib/kafka/data-0/kafka-log0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = []
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.cold.partition.snapshot.interval.ms = 300000
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = HTTPS
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transaction.two.phase.commit.enable = false
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false

2026-02-12 18:32:04 INFO  [kafka-0-metadata-loader-event-handler] MetadataLoader:306 - [MetadataLoader id=0] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=0) with a snapshot at offset 12
2026-02-12 18:32:04 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:69 - [BrokerLifecycleManager id=0] The broker has caught up. Transitioning from STARTING to RECOVERY.
2026-02-12 18:32:04 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for the controller to acknowledge that we are caught up
2026-02-12 18:32:04 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for the initial broker metadata update to be published
2026-02-12 18:32:04 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for the initial broker metadata update to be published
2026-02-12 18:32:04 INFO  [main] AbstractKubernetesConfigProvider:68 - Configuring Kubernetes Secret config provider with configuration {}
2026-02-12 18:32:04 INFO  [main] AbstractKubernetesConfigProvider:62 - Closing Kubernetes Secret config provider
2026-02-12 18:32:04 INFO  [main] AbstractConfig:380 - KafkaConfig values: 
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = CONTROLPLANE-9090://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9090,REPLICATION-9091://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9091,PLAIN-9092://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9092,TLS-9093://my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc:9093
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLPLANE-9090
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@my-cluster-dual-role-0.my-cluster-kafka-brokers.ksql0491.svc.cluster.local:9090]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.regex.refresh.interval.ms = 600000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.rebalance.protocols = [classic, consumer, streams]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.assignors = [simple]
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.share.sessions = 2000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 2000
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	group.streams.heartbeat.interval.ms = 5000
	group.streams.max.heartbeat.interval.ms = 15000
	group.streams.max.session.timeout.ms = 60000
	group.streams.max.size = 2147483647
	group.streams.max.standby.replicas = 2
	group.streams.min.heartbeat.interval.ms = 5000
	group.streams.min.session.timeout.ms = 45000
	group.streams.num.standby.replicas = 0
	group.streams.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = REPLICATION-9091
	internal.metadata.delete.delay.millis = 60000
	internal.metadata.log.segment.bytes = null
	internal.metadata.max.batch.size.in.bytes = 8388608
	internal.metadata.max.fetch.size.in.bytes = 8388608
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	listener.security.protocol.map = CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:PLAINTEXT,TLS-9093:SSL
	listeners = CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092,TLS-9093://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data-0/kafka-log0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = /var/lib/kafka/data-0/kafka-log0
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = []
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.algorithm = RS256
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.seconds = 300
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.client.credentials.client.id = null
	sasl.oauthbearer.client.credentials.client.secret = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
	sasl.oauthbearer.scope = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.cold.partition.snapshot.interval.ms = 300000
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = HTTPS
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transaction.two.phase.commit.enable = false
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false

2026-02-12 18:32:04 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:69 - [BrokerLifecycleManager id=0] The broker is in RECOVERY.
2026-02-12 18:32:04 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for the broker to be unfenced
2026-02-12 18:32:04 INFO  [quorum-controller-0-event-handler] BrokerHeartbeatManager:413 - [QuorumController id=0] The request from broker 0 to unfence has been granted because it has caught up with the offset of its register broker record 13.
2026-02-12 18:32:04 INFO  [quorum-controller-0-event-handler] ClusterControlManager:673 - [QuorumController id=0] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 0: BrokerRegistrationChangeRecord(brokerId=0, brokerEpoch=13, fenced=-1, inControlledShutdown=0, logDirs=[])
2026-02-12 18:32:04 INFO  [broker-0-lifecycle-manager-event-handler] BrokerLifecycleManager:69 - [BrokerLifecycleManager id=0] The broker has been unfenced. Transitioning from RECOVERY to RUNNING.
2026-02-12 18:32:04 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for the broker to be unfenced
2026-02-12 18:32:04 INFO  [main] EndpointReadyFutures:168 - authorizerStart completed for endpoint REPLICATION-9091. Endpoint is now READY.
2026-02-12 18:32:04 INFO  [main] EndpointReadyFutures:168 - authorizerStart completed for endpoint PLAIN-9092. Endpoint is now READY.
2026-02-12 18:32:04 INFO  [main] EndpointReadyFutures:168 - authorizerStart completed for endpoint TLS-9093. Endpoint is now READY.
2026-02-12 18:32:04 INFO  [main] SocketServer:69 - [SocketServer listenerType=BROKER, nodeId=0] Enabling request processing.
2026-02-12 18:32:04 INFO  [main] DataPlaneAcceptor:69 - Awaiting socket connections on 0.0.0.0:9093.
2026-02-12 18:32:04 INFO  [main] DataPlaneAcceptor:69 - Awaiting socket connections on 0.0.0.0:9091.
2026-02-12 18:32:04 INFO  [main] DataPlaneAcceptor:69 - Awaiting socket connections on 0.0.0.0:9092.
2026-02-12 18:32:04 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for all of the authorizer futures to be completed
2026-02-12 18:32:04 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for all of the authorizer futures to be completed
2026-02-12 18:32:04 INFO  [main] BrokerServer:57 - [BrokerServer id=0] Waiting for all of the SocketServer Acceptors to be started
2026-02-12 18:32:04 INFO  [main] BrokerServer:60 - [BrokerServer id=0] Finished waiting for all of the SocketServer Acceptors to be started
2026-02-12 18:32:04 INFO  [main] BrokerServer:69 - [BrokerServer id=0] Transition from STARTING to STARTED
2026-02-12 18:32:04 INFO  [main] AppInfoParser:125 - Kafka version: 4.1.1
2026-02-12 18:32:04 INFO  [main] AppInfoParser:126 - Kafka commitId: be816b82d25370ce
2026-02-12 18:32:04 INFO  [main] AppInfoParser:127 - Kafka startTimeMs: 1770921124233
2026-02-12 18:32:04 INFO  [main] KafkaRaftServer:69 - [KafkaRaftServer nodeId=0] Kafka Server started
2026-02-12 18:33:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 344 controller events were completed, which took an average of 19.82 ms each. The slowest event was writeNoOpRecord(458174975), which took 512.10 ms.
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:701 - [QuorumController id=0] CreateTopics result(s): CreatableTopic(name='kafkasql-journal', numPartitions=-1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='delete'), CreatableTopicConfig(name='min.insync.replicas', value='1'), CreatableTopicConfig(name='retention.ms', value='-1'), CreatableTopicConfig(name='retention.bytes', value='-1')]): SUCCESS
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:436 - [QuorumController id=0] Replayed TopicRecord for topic kafkasql-journal with topic ID aST-CnGYR6uhRCuPI2-BuQ.
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-journal') which set configuration cleanup.policy to delete
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-journal') which set configuration min.insync.replicas to 1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-journal') which set configuration retention.ms to -1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-journal') which set configuration retention.bytes to -1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:600 - [QuorumController id=0] Removed ELRs from 0 partitions of topic kafkasql-journal.
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition kafkasql-journal-0 with topic ID aST-CnGYR6uhRCuPI2-BuQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:34 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Transitioning 1 partition(s) to local leaders.
2026-02-12 18:33:34 INFO  [kafka-0-metadata-loader-event-handler] ReplicaFetcherManager:69 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafkasql-journal-0)
2026-02-12 18:33:34 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition kafkasql-journal-0 with topic id aST-CnGYR6uhRCuPI2-BuQ.
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:701 - [QuorumController id=0] CreateTopics result(s): CreatableTopic(name='kafkasql-snapshots', numPartitions=-1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='delete'), CreatableTopicConfig(name='min.insync.replicas', value='1'), CreatableTopicConfig(name='retention.ms', value='-1'), CreatableTopicConfig(name='retention.bytes', value='-1')]): SUCCESS
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:436 - [QuorumController id=0] Replayed TopicRecord for topic kafkasql-snapshots with topic ID gazDRWMgSnWVX3ELJ_OIgg.
2026-02-12 18:33:34 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=kafkasql-journal-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-snapshots') which set configuration cleanup.policy to delete
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-snapshots') which set configuration min.insync.replicas to 1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-snapshots') which set configuration retention.ms to -1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='kafkasql-snapshots') which set configuration retention.bytes to -1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:600 - [QuorumController id=0] Removed ELRs from 0 partitions of topic kafkasql-snapshots.
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition kafkasql-snapshots-0 with topic ID gazDRWMgSnWVX3ELJ_OIgg and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:34 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition kafkasql-journal-0 in /var/lib/kafka/data-0/kafka-log0/kafkasql-journal-0 with properties {cleanup.policy=delete, min.insync.replicas=1, retention.bytes=-1, retention.ms=-1}
2026-02-12 18:33:34 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition kafkasql-journal-0 broker=0] No checkpointed highwatermark is found for partition kafkasql-journal-0
2026-02-12 18:33:34 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition kafkasql-journal-0 broker=0] Log loaded for partition kafkasql-journal-0 with initial high watermark 0
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:701 - [QuorumController id=0] CreateTopics result(s): CreatableTopic(name='registry-events', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='delete'), CreatableTopicConfig(name='min.insync.replicas', value='1'), CreatableTopicConfig(name='retention.ms', value='-1'), CreatableTopicConfig(name='retention.bytes', value='-1')]): SUCCESS
2026-02-12 18:33:34 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader kafkasql-journal-0 with topic id Some(aST-CnGYR6uhRCuPI2-BuQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:436 - [QuorumController id=0] Replayed TopicRecord for topic registry-events with topic ID U-PQ28SIQJyf--Ylxk0Xuw.
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='registry-events') which set configuration cleanup.policy to delete
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='registry-events') which set configuration min.insync.replicas to 1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='registry-events') which set configuration retention.ms to -1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='registry-events') which set configuration retention.bytes to -1
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:600 - [QuorumController id=0] Removed ELRs from 0 partitions of topic registry-events.
2026-02-12 18:33:34 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition registry-events-0 with topic ID U-PQ28SIQJyf--Ylxk0Xuw and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:69 - [DynamicConfigPublisher broker id=0] Updating topic kafkasql-journal with new configuration : cleanup.policy -> delete,min.insync.replicas -> 1,retention.ms -> -1,retention.bytes -> -1
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Transitioning 1 partition(s) to local leaders.
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] ReplicaFetcherManager:69 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafkasql-snapshots-0)
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition kafkasql-snapshots-0 with topic id gazDRWMgSnWVX3ELJ_OIgg.
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=kafkasql-snapshots-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition kafkasql-snapshots-0 in /var/lib/kafka/data-0/kafka-log0/kafkasql-snapshots-0 with properties {cleanup.policy=delete, min.insync.replicas=1, retention.bytes=-1, retention.ms=-1}
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition kafkasql-snapshots-0 broker=0] No checkpointed highwatermark is found for partition kafkasql-snapshots-0
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition kafkasql-snapshots-0 broker=0] Log loaded for partition kafkasql-snapshots-0 with initial high watermark 0
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader kafkasql-snapshots-0 with topic id Some(gazDRWMgSnWVX3ELJ_OIgg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:69 - [DynamicConfigPublisher broker id=0] Updating topic kafkasql-snapshots with new configuration : cleanup.policy -> delete,min.insync.replicas -> 1,retention.ms -> -1,retention.bytes -> -1
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Transitioning 1 partition(s) to local leaders.
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] ReplicaFetcherManager:69 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(registry-events-0)
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition registry-events-0 with topic id U-PQ28SIQJyf--Ylxk0Xuw.
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=registry-events-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition registry-events-0 in /var/lib/kafka/data-0/kafka-log0/registry-events-0 with properties {cleanup.policy=delete, min.insync.replicas=1, retention.bytes=-1, retention.ms=-1}
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition registry-events-0 broker=0] No checkpointed highwatermark is found for partition registry-events-0
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition registry-events-0 broker=0] Log loaded for partition registry-events-0 with initial high watermark 0
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader registry-events-0 with topic id Some(U-PQ28SIQJyf--Ylxk0Xuw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:35 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:69 - [DynamicConfigPublisher broker id=0] Updating topic registry-events with new configuration : cleanup.policy -> delete,min.insync.replicas -> 1,retention.ms -> -1,retention.bytes -> -1
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:701 - [QuorumController id=0] CreateTopics result(s): CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]): SUCCESS
2026-02-12 18:33:45 INFO  [data-plane-kafka-request-handler-6] DefaultAutoTopicCreationManager:69 - Sent auto-creation request for Set(__consumer_offsets) to the active controller.
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:436 - [QuorumController id=0] Replayed TopicRecord for topic __consumer_offsets with topic ID k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration compression.type to producer
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration cleanup.policy to compact
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ConfigurationControlManager:537 - [QuorumController id=0] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration segment.bytes to 104857600
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-0 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-1 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-2 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-3 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-4 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-5 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-6 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-7 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-8 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-9 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-10 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-11 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-12 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-13 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-14 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-15 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-16 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-17 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-18 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-19 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-20 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-21 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-22 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-23 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-24 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-25 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-26 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-27 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-28 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-29 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-30 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-31 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-32 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-33 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-34 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-35 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-36 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-37 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-38 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-39 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-40 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-41 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-42 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-43 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-44 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-45 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-46 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-47 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-48 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [quorum-controller-0-event-handler] ReplicationControlManager:450 - [QuorumController id=0] Replayed PartitionRecord for new partition __consumer_offsets-49 with topic ID k8tEogSQRIKNJWuoSPl0TQ and PartitionRegistration(replicas=[0], directories=[WcnePDcdf5I1t1eNvMsYvA], isr=[0], removingReplicas=[], addingReplicas=[], elr=[], lastKnownElr=[], leader=0, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0).
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Transitioning 50 partition(s) to local leaders.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] ReplicaFetcherManager:69 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2)
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-13 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-13, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-13 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-13 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-46 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-46, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-46 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-46 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-9 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-9, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-9 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-9 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-42 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-42, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-42 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-42 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-21 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-21, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-21 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-21 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-17 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-17, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-17 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-17 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-30 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-30, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-30 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-30 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-26 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-26, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-26 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-26 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-5 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-5, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-5 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-5 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-38 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-38, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-38 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-38 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-1 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-1, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-1 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-1 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-34 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-34, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-34 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-34 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-16 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-16, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-16 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-16 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-45 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-45, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-45 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-45 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-12 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-12, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-12 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-12 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-41 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-41, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-41 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-41 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-24 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-24, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-24 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-24 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-20 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-20, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-20 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-20 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-49 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-49, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-49 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-49 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-0 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-0, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-0 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-0 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-29 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-29, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-29 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-29 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-25 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-25, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-25 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-25 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-8 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-8, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-8 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-8 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-37 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-37, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-37 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-37 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-4 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-4, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-4 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-4 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-33 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-33, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-33 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-33 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-15 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-15, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-15 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0
2026-02-12 18:33:45 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-15 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-48 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-48, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-48 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-48 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-11 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-11, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-11 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-11 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-44 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-44, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-44 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-44 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-23 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-23, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-23 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-23 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-19 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-19, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-19 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-19 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-32 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-32, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-32 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-32 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-28 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-28, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-28 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-28 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-7 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-7, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-7 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-7 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-40 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-40, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-40 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-40 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-3 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-3, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-3 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-3 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-36 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-36, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-36 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-36 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-47 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-47, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-47 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-47 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-14 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-14, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-14 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-14 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-43 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-43, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-43 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-43 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-10 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-10, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-10 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-10 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-22 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-22, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-22 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-22 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-18 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-18, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-18 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-18 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-31 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-31, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-31 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-31 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-27 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-27, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-27 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-27 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-39 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-39, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-39 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-39 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-6 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-6, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-6 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-6 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-35 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-35, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-35 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-35 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Creating new partition __consumer_offsets-2 with topic id k8tEogSQRIKNJWuoSPl0TQ.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] UnifiedLog:2449 - [LogLoader partition=__consumer_offsets-2, dir=/var/lib/kafka/data-0/kafka-log0] Loading producer state till offset 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] LogManager:69 - Created log for partition __consumer_offsets-2 in /var/lib/kafka/data-0/kafka-log0/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] Partition:69 - [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] logger:69 - [Broker id=0] Leader __consumer_offsets-2 with topic id Some(k8tEogSQRIKNJWuoSPl0TQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-13 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-46 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-9 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-42 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-21 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-17 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-30 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-26 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-5 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-38 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-1 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-34 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-16 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-45 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-12 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-41 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-24 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-20 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-49 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-0 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-29 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-25 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-8 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-37 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-4 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-33 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-15 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-48 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-11 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-44 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-23 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-19 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-32 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-28 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-7 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-40 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-3 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-36 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-47 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-14 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-43 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-10 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-22 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-18 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-31 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-27 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-39 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-6 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-35 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] CoordinatorRuntime:2387 - [GroupCoordinator id=0] Scheduling loading of metadata from __consumer_offsets-2 with epoch 0
2026-02-12 18:33:46 INFO  [kafka-0-metadata-loader-event-handler] DynamicConfigPublisher:69 - [DynamicConfigPublisher broker id=0] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-39 with epoch 0 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-37 with epoch 0 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-29 with epoch 0 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-19 with epoch 0 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-42 with epoch 0 in 22ms where 22ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-30 with epoch 0 in 13ms where 13ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-48 with epoch 0 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-14 with epoch 0 in 13ms where 13ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-5 with epoch 0 in 15ms where 15ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-31 with epoch 0 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-1 with epoch 0 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-20 with epoch 0 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-16 with epoch 0 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-27 with epoch 0 in 20ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-9 with epoch 0 in 22ms where 22ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-24 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-49 with epoch 0 in 5ms where 5ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-41 with epoch 0 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-23 with epoch 0 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-40 with epoch 0 in 20ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-4 with epoch 0 in 6ms where 6ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-34 with epoch 0 in 7ms where 7ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-8 with epoch 0 in 7ms where 7ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-21 with epoch 0 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-7 with epoch 0 in 15ms where 15ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-46 with epoch 0 in 22ms where 22ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-6 with epoch 0 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-38 with epoch 0 in 20ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-33 with epoch 0 in 7ms where 7ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-3 with epoch 0 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-43 with epoch 0 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-17 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-10 with epoch 0 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-36 with epoch 0 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-11 with epoch 0 in 20ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-2 with epoch 0 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-12 with epoch 0 in 20ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-44 with epoch 0 in 7ms where 7ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-15 with epoch 0 in 15ms where 15ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-45 with epoch 0 in 17ms where 17ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-2] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-22 with epoch 0 in 7ms where 7ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-35 with epoch 0 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-28 with epoch 0 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-47 with epoch 0 in 19ms where 19ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-0 with epoch 0 in 18ms where 18ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-13 with epoch 0 in 23ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-25 with epoch 0 in 20ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-18 with epoch 0 in 15ms where 15ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-1] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-26 with epoch 0 in 20ms where 20ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-3] CoordinatorRuntime:715 - [GroupCoordinator id=0] Finished loading of metadata from __consumer_offsets-32 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=47] Dynamic member with unknown member id joins group apicurio-96285575-eba7-4c69-a904-e14277b3e3a2 in Empty state. Created a new member id apicurio-consumer-7d5abbd4-9881-434b-b5b3-952e3185841b-c338fb44-9455-4dba-9aab-db27422c7607 and requesting the member to rejoin with this id.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=47] Pending dynamic member with id apicurio-consumer-7d5abbd4-9881-434b-b5b3-952e3185841b-c338fb44-9455-4dba-9aab-db27422c7607 joins group apicurio-96285575-eba7-4c69-a904-e14277b3e3a2 in Empty state. Adding to the group now.
2026-02-12 18:33:46 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=47] Preparing to rebalance group apicurio-96285575-eba7-4c69-a904-e14277b3e3a2 in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-7d5abbd4-9881-434b-b5b3-952e3185841b-c338fb44-9455-4dba-9aab-db27422c7607 with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-7d5abbd4-9881-434b-b5b3-952e3185841b-c338fb44-9455-4dba-9aab-db27422c7607).
2026-02-12 18:33:49 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=47] Stabilized group apicurio-96285575-eba7-4c69-a904-e14277b3e3a2 generation 1 with 1 members.
2026-02-12 18:33:49 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:7366 - [GroupCoordinator id=0 topic=__consumer_offsets partition=47] Assignment received from leader apicurio-consumer-7d5abbd4-9881-434b-b5b3-952e3185841b-c338fb44-9455-4dba-9aab-db27422c7607 for group apicurio-96285575-eba7-4c69-a904-e14277b3e3a2 for generation 1. The group has 1 members, 0 of which are static.
2026-02-12 18:33:56 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:7979 - [GroupCoordinator id=0 topic=__consumer_offsets partition=47] [Group apicurio-96285575-eba7-4c69-a904-e14277b3e3a2] Member apicurio-consumer-7d5abbd4-9881-434b-b5b3-952e3185841b-c338fb44-9455-4dba-9aab-db27422c7607 has left group through explicit `LeaveGroup` request; client reason: the consumer is being closed
2026-02-12 18:33:56 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=47] Preparing to rebalance group apicurio-96285575-eba7-4c69-a904-e14277b3e3a2 in state PreparingRebalance with old generation 1 (reason: explicit `LeaveGroup` request for (apicurio-consumer-7d5abbd4-9881-434b-b5b3-952e3185841b-c338fb44-9455-4dba-9aab-db27422c7607) members.).
2026-02-12 18:33:56 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6588 - [GroupCoordinator id=0 topic=__consumer_offsets partition=47] Group apicurio-96285575-eba7-4c69-a904-e14277b3e3a2 with generation 2 is now empty.
2026-02-12 18:33:56 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=6] Dynamic member with unknown member id joins group apicurio-f9e0541f-6af3-489b-a9f8-18e4ff953b25 in Empty state. Created a new member id apicurio-consumer-997d11e2-8059-4c9d-ae4d-d9f19d34b4fe-88275dd5-7289-4939-b10c-c136c04f00e2 and requesting the member to rejoin with this id.
2026-02-12 18:33:56 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=6] Pending dynamic member with id apicurio-consumer-997d11e2-8059-4c9d-ae4d-d9f19d34b4fe-88275dd5-7289-4939-b10c-c136c04f00e2 joins group apicurio-f9e0541f-6af3-489b-a9f8-18e4ff953b25 in Empty state. Adding to the group now.
2026-02-12 18:33:56 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=6] Preparing to rebalance group apicurio-f9e0541f-6af3-489b-a9f8-18e4ff953b25 in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-997d11e2-8059-4c9d-ae4d-d9f19d34b4fe-88275dd5-7289-4939-b10c-c136c04f00e2 with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-997d11e2-8059-4c9d-ae4d-d9f19d34b4fe-88275dd5-7289-4939-b10c-c136c04f00e2).
2026-02-12 18:33:59 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=6] Stabilized group apicurio-f9e0541f-6af3-489b-a9f8-18e4ff953b25 generation 1 with 1 members.
2026-02-12 18:33:59 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:7366 - [GroupCoordinator id=0 topic=__consumer_offsets partition=6] Assignment received from leader apicurio-consumer-997d11e2-8059-4c9d-ae4d-d9f19d34b4fe-88275dd5-7289-4939-b10c-c136c04f00e2 for group apicurio-f9e0541f-6af3-489b-a9f8-18e4ff953b25 for generation 1. The group has 1 members, 0 of which are static.
2026-02-12 18:34:01 INFO  [quorum-controller-0-event-handler] ProducerIdControlManager:116 - [QuorumController id=0] Replaying ProducerIdsRecord ProducerIdsRecord(brokerId=0, brokerEpoch=13, nextProducerId=1000)
2026-02-12 18:34:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 333 controller events were completed, which took an average of 20.64 ms each. The slowest event was writeNoOpRecord(2100103642), which took 238.42 ms.
2026-02-12 18:34:01 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=8] Dynamic member with unknown member id joins group apicurio-86b99e37-94ee-4230-8819-c0bc295d6fb6 in Empty state. Created a new member id apicurio-consumer-14b6bd71-2fe1-4baf-a619-a8232c7998b2-b39c577e-cf72-4b85-ace9-906159cbd8f5 and requesting the member to rejoin with this id.
2026-02-12 18:34:01 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=8] Pending dynamic member with id apicurio-consumer-14b6bd71-2fe1-4baf-a619-a8232c7998b2-b39c577e-cf72-4b85-ace9-906159cbd8f5 joins group apicurio-86b99e37-94ee-4230-8819-c0bc295d6fb6 in Empty state. Adding to the group now.
2026-02-12 18:34:01 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=8] Preparing to rebalance group apicurio-86b99e37-94ee-4230-8819-c0bc295d6fb6 in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-14b6bd71-2fe1-4baf-a619-a8232c7998b2-b39c577e-cf72-4b85-ace9-906159cbd8f5 with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-14b6bd71-2fe1-4baf-a619-a8232c7998b2-b39c577e-cf72-4b85-ace9-906159cbd8f5).
2026-02-12 18:34:04 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=8] Stabilized group apicurio-86b99e37-94ee-4230-8819-c0bc295d6fb6 generation 1 with 1 members.
2026-02-12 18:34:10 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=11] Dynamic member with unknown member id joins group apicurio-d34abac8-932d-4f62-8d60-812799fb7bed in Empty state. Created a new member id apicurio-consumer-e71f9013-f6ae-4107-b0bb-de73eb42e859-2fa8d40a-fa09-4852-8a2c-5446050fc4d8 and requesting the member to rejoin with this id.
2026-02-12 18:34:10 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=11] Pending dynamic member with id apicurio-consumer-e71f9013-f6ae-4107-b0bb-de73eb42e859-2fa8d40a-fa09-4852-8a2c-5446050fc4d8 joins group apicurio-d34abac8-932d-4f62-8d60-812799fb7bed in Empty state. Adding to the group now.
2026-02-12 18:34:10 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=11] Preparing to rebalance group apicurio-d34abac8-932d-4f62-8d60-812799fb7bed in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-e71f9013-f6ae-4107-b0bb-de73eb42e859-2fa8d40a-fa09-4852-8a2c-5446050fc4d8 with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-e71f9013-f6ae-4107-b0bb-de73eb42e859-2fa8d40a-fa09-4852-8a2c-5446050fc4d8).
2026-02-12 18:34:13 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=11] Stabilized group apicurio-d34abac8-932d-4f62-8d60-812799fb7bed generation 1 with 1 members.
2026-02-12 18:34:13 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:7366 - [GroupCoordinator id=0 topic=__consumer_offsets partition=11] Assignment received from leader apicurio-consumer-e71f9013-f6ae-4107-b0bb-de73eb42e859-2fa8d40a-fa09-4852-8a2c-5446050fc4d8 for group apicurio-d34abac8-932d-4f62-8d60-812799fb7bed for generation 1. The group has 1 members, 0 of which are static.
2026-02-12 18:34:19 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:7979 - [GroupCoordinator id=0 topic=__consumer_offsets partition=11] [Group apicurio-d34abac8-932d-4f62-8d60-812799fb7bed] Member apicurio-consumer-e71f9013-f6ae-4107-b0bb-de73eb42e859-2fa8d40a-fa09-4852-8a2c-5446050fc4d8 has left group through explicit `LeaveGroup` request; client reason: the consumer is being closed
2026-02-12 18:34:19 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=11] Preparing to rebalance group apicurio-d34abac8-932d-4f62-8d60-812799fb7bed in state PreparingRebalance with old generation 1 (reason: explicit `LeaveGroup` request for (apicurio-consumer-e71f9013-f6ae-4107-b0bb-de73eb42e859-2fa8d40a-fa09-4852-8a2c-5446050fc4d8) members.).
2026-02-12 18:34:19 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6588 - [GroupCoordinator id=0 topic=__consumer_offsets partition=11] Group apicurio-d34abac8-932d-4f62-8d60-812799fb7bed with generation 2 is now empty.
2026-02-12 18:34:19 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Dynamic member with unknown member id joins group apicurio-f48a9f40-fed7-4b0a-a69d-1be00c987b71 in Empty state. Created a new member id apicurio-consumer-13b7ed98-c60d-4ac6-90be-edac9d6e1a7f-576068cd-511b-493a-ac5b-680d09696a9c and requesting the member to rejoin with this id.
2026-02-12 18:34:19 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Pending dynamic member with id apicurio-consumer-13b7ed98-c60d-4ac6-90be-edac9d6e1a7f-576068cd-511b-493a-ac5b-680d09696a9c joins group apicurio-f48a9f40-fed7-4b0a-a69d-1be00c987b71 in Empty state. Adding to the group now.
2026-02-12 18:34:19 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Preparing to rebalance group apicurio-f48a9f40-fed7-4b0a-a69d-1be00c987b71 in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-13b7ed98-c60d-4ac6-90be-edac9d6e1a7f-576068cd-511b-493a-ac5b-680d09696a9c with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-13b7ed98-c60d-4ac6-90be-edac9d6e1a7f-576068cd-511b-493a-ac5b-680d09696a9c).
2026-02-12 18:34:22 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Stabilized group apicurio-f48a9f40-fed7-4b0a-a69d-1be00c987b71 generation 1 with 1 members.
2026-02-12 18:34:22 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:7366 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Assignment received from leader apicurio-consumer-13b7ed98-c60d-4ac6-90be-edac9d6e1a7f-576068cd-511b-493a-ac5b-680d09696a9c for group apicurio-f48a9f40-fed7-4b0a-a69d-1be00c987b71 for generation 1. The group has 1 members, 0 of which are static.
2026-02-12 18:34:25 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=27] Dynamic member with unknown member id joins group apicurio-a1c0e1c8-1259-4c5a-bee9-3ce7de5f3fdf in Empty state. Created a new member id apicurio-consumer-ac659e48-56b6-49ee-abb9-d6d7265cd5d5-e7c7b94b-dd7a-430d-91cb-7c60a927ef31 and requesting the member to rejoin with this id.
2026-02-12 18:34:25 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=27] Pending dynamic member with id apicurio-consumer-ac659e48-56b6-49ee-abb9-d6d7265cd5d5-e7c7b94b-dd7a-430d-91cb-7c60a927ef31 joins group apicurio-a1c0e1c8-1259-4c5a-bee9-3ce7de5f3fdf in Empty state. Adding to the group now.
2026-02-12 18:34:25 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=27] Preparing to rebalance group apicurio-a1c0e1c8-1259-4c5a-bee9-3ce7de5f3fdf in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-ac659e48-56b6-49ee-abb9-d6d7265cd5d5-e7c7b94b-dd7a-430d-91cb-7c60a927ef31 with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-ac659e48-56b6-49ee-abb9-d6d7265cd5d5-e7c7b94b-dd7a-430d-91cb-7c60a927ef31).
2026-02-12 18:34:28 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=27] Stabilized group apicurio-a1c0e1c8-1259-4c5a-bee9-3ce7de5f3fdf generation 1 with 1 members.
2026-02-12 18:34:33 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Dynamic member with unknown member id joins group apicurio-7871782a-d287-43b2-a93d-3c823b7824c3 in Empty state. Created a new member id apicurio-consumer-167309ad-0db6-479f-9041-1d5a0a6104eb-6284e565-2b37-4e84-8dec-0947308195b6 and requesting the member to rejoin with this id.
2026-02-12 18:34:33 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Pending dynamic member with id apicurio-consumer-167309ad-0db6-479f-9041-1d5a0a6104eb-6284e565-2b37-4e84-8dec-0947308195b6 joins group apicurio-7871782a-d287-43b2-a93d-3c823b7824c3 in Empty state. Adding to the group now.
2026-02-12 18:34:33 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Preparing to rebalance group apicurio-7871782a-d287-43b2-a93d-3c823b7824c3 in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-167309ad-0db6-479f-9041-1d5a0a6104eb-6284e565-2b37-4e84-8dec-0947308195b6 with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-167309ad-0db6-479f-9041-1d5a0a6104eb-6284e565-2b37-4e84-8dec-0947308195b6).
2026-02-12 18:34:36 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Stabilized group apicurio-7871782a-d287-43b2-a93d-3c823b7824c3 generation 1 with 1 members.
2026-02-12 18:34:36 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:7366 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Assignment received from leader apicurio-consumer-167309ad-0db6-479f-9041-1d5a0a6104eb-6284e565-2b37-4e84-8dec-0947308195b6 for group apicurio-7871782a-d287-43b2-a93d-3c823b7824c3 for generation 1. The group has 1 members, 0 of which are static.
2026-02-12 18:34:41 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:7979 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] [Group apicurio-7871782a-d287-43b2-a93d-3c823b7824c3] Member apicurio-consumer-167309ad-0db6-479f-9041-1d5a0a6104eb-6284e565-2b37-4e84-8dec-0947308195b6 has left group through explicit `LeaveGroup` request; client reason: the consumer is being closed
2026-02-12 18:34:41 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Preparing to rebalance group apicurio-7871782a-d287-43b2-a93d-3c823b7824c3 in state PreparingRebalance with old generation 1 (reason: explicit `LeaveGroup` request for (apicurio-consumer-167309ad-0db6-479f-9041-1d5a0a6104eb-6284e565-2b37-4e84-8dec-0947308195b6) members.).
2026-02-12 18:34:41 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6588 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Group apicurio-7871782a-d287-43b2-a93d-3c823b7824c3 with generation 2 is now empty.
2026-02-12 18:34:42 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=36] Dynamic member with unknown member id joins group apicurio-991029c8-9382-421f-a678-8cda22726f97 in Empty state. Created a new member id apicurio-consumer-5f4d0c29-e6a7-475b-af54-f4b7f69ff415-0a397aeb-ab33-41fa-bf0e-c15416933a95 and requesting the member to rejoin with this id.
2026-02-12 18:34:42 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=36] Pending dynamic member with id apicurio-consumer-5f4d0c29-e6a7-475b-af54-f4b7f69ff415-0a397aeb-ab33-41fa-bf0e-c15416933a95 joins group apicurio-991029c8-9382-421f-a678-8cda22726f97 in Empty state. Adding to the group now.
2026-02-12 18:34:42 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=36] Preparing to rebalance group apicurio-991029c8-9382-421f-a678-8cda22726f97 in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-5f4d0c29-e6a7-475b-af54-f4b7f69ff415-0a397aeb-ab33-41fa-bf0e-c15416933a95 with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-5f4d0c29-e6a7-475b-af54-f4b7f69ff415-0a397aeb-ab33-41fa-bf0e-c15416933a95).
2026-02-12 18:34:45 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=36] Stabilized group apicurio-991029c8-9382-421f-a678-8cda22726f97 generation 1 with 1 members.
2026-02-12 18:34:45 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:7366 - [GroupCoordinator id=0 topic=__consumer_offsets partition=36] Assignment received from leader apicurio-consumer-5f4d0c29-e6a7-475b-af54-f4b7f69ff415-0a397aeb-ab33-41fa-bf0e-c15416933a95 for group apicurio-991029c8-9382-421f-a678-8cda22726f97 for generation 1. The group has 1 members, 0 of which are static.
2026-02-12 18:34:47 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6691 - [GroupCoordinator id=0 topic=__consumer_offsets partition=6] Member apicurio-consumer-997d11e2-8059-4c9d-ae4d-d9f19d34b4fe-88275dd5-7289-4939-b10c-c136c04f00e2 in group apicurio-f9e0541f-6af3-489b-a9f8-18e4ff953b25 has failed, removing it from the group.
2026-02-12 18:34:47 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=6] Preparing to rebalance group apicurio-f9e0541f-6af3-489b-a9f8-18e4ff953b25 in state PreparingRebalance with old generation 1 (reason: removing member apicurio-consumer-997d11e2-8059-4c9d-ae4d-d9f19d34b4fe-88275dd5-7289-4939-b10c-c136c04f00e2 on heartbeat expiration.).
2026-02-12 18:34:47 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6588 - [GroupCoordinator id=0 topic=__consumer_offsets partition=6] Group apicurio-f9e0541f-6af3-489b-a9f8-18e4ff953b25 with generation 2 is now empty.
2026-02-12 18:34:47 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6335 - [GroupCoordinator id=0 topic=__consumer_offsets partition=4] Dynamic member with unknown member id joins group apicurio-760d883e-1c7d-4ea0-96a7-4c6d2dc1285d in Empty state. Created a new member id apicurio-consumer-cbb24cc1-b69a-4a48-bd8d-c5da536973a5-db8e2677-84a6-42c6-a287-9e2afb672444 and requesting the member to rejoin with this id.
2026-02-12 18:34:47 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6405 - [GroupCoordinator id=0 topic=__consumer_offsets partition=4] Pending dynamic member with id apicurio-consumer-cbb24cc1-b69a-4a48-bd8d-c5da536973a5-db8e2677-84a6-42c6-a287-9e2afb672444 joins group apicurio-760d883e-1c7d-4ea0-96a7-4c6d2dc1285d in Empty state. Adding to the group now.
2026-02-12 18:34:47 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=4] Preparing to rebalance group apicurio-760d883e-1c7d-4ea0-96a7-4c6d2dc1285d in state PreparingRebalance with old generation 0 (reason: Adding new member apicurio-consumer-cbb24cc1-b69a-4a48-bd8d-c5da536973a5-db8e2677-84a6-42c6-a287-9e2afb672444 with group instance id null; client reason: need to re-join with the given member-id: apicurio-consumer-cbb24cc1-b69a-4a48-bd8d-c5da536973a5-db8e2677-84a6-42c6-a287-9e2afb672444).
2026-02-12 18:34:49 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6691 - [GroupCoordinator id=0 topic=__consumer_offsets partition=8] Member apicurio-consumer-14b6bd71-2fe1-4baf-a619-a8232c7998b2-b39c577e-cf72-4b85-ace9-906159cbd8f5 in group apicurio-86b99e37-94ee-4230-8819-c0bc295d6fb6 has failed, removing it from the group.
2026-02-12 18:34:49 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=8] Preparing to rebalance group apicurio-86b99e37-94ee-4230-8819-c0bc295d6fb6 in state PreparingRebalance with old generation 1 (reason: removing member apicurio-consumer-14b6bd71-2fe1-4baf-a619-a8232c7998b2-b39c577e-cf72-4b85-ace9-906159cbd8f5 on heartbeat expiration.).
2026-02-12 18:34:49 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6588 - [GroupCoordinator id=0 topic=__consumer_offsets partition=8] Group apicurio-86b99e37-94ee-4230-8819-c0bc295d6fb6 with generation 2 is now empty.
2026-02-12 18:34:50 INFO  [group-coordinator-event-processor-2] GroupMetadataManager:6607 - [GroupCoordinator id=0 topic=__consumer_offsets partition=4] Stabilized group apicurio-760d883e-1c7d-4ea0-96a7-4c6d2dc1285d generation 1 with 1 members.
2026-02-12 18:34:50 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:7366 - [GroupCoordinator id=0 topic=__consumer_offsets partition=4] Assignment received from leader apicurio-consumer-cbb24cc1-b69a-4a48-bd8d-c5da536973a5-db8e2677-84a6-42c6-a287-9e2afb672444 for group apicurio-760d883e-1c7d-4ea0-96a7-4c6d2dc1285d for generation 1. The group has 1 members, 0 of which are static.
2026-02-12 18:35:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 10.05 ms each. The slowest event was writeNoOpRecord(2023233061), which took 79.11 ms.
2026-02-12 18:35:10 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6691 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Member apicurio-consumer-13b7ed98-c60d-4ac6-90be-edac9d6e1a7f-576068cd-511b-493a-ac5b-680d09696a9c in group apicurio-f48a9f40-fed7-4b0a-a69d-1be00c987b71 has failed, removing it from the group.
2026-02-12 18:35:10 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Preparing to rebalance group apicurio-f48a9f40-fed7-4b0a-a69d-1be00c987b71 in state PreparingRebalance with old generation 1 (reason: removing member apicurio-consumer-13b7ed98-c60d-4ac6-90be-edac9d6e1a7f-576068cd-511b-493a-ac5b-680d09696a9c on heartbeat expiration.).
2026-02-12 18:35:10 INFO  [group-coordinator-event-processor-3] GroupMetadataManager:6588 - [GroupCoordinator id=0 topic=__consumer_offsets partition=25] Group apicurio-f48a9f40-fed7-4b0a-a69d-1be00c987b71 with generation 2 is now empty.
2026-02-12 18:35:13 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6691 - [GroupCoordinator id=0 topic=__consumer_offsets partition=27] Member apicurio-consumer-ac659e48-56b6-49ee-abb9-d6d7265cd5d5-e7c7b94b-dd7a-430d-91cb-7c60a927ef31 in group apicurio-a1c0e1c8-1259-4c5a-bee9-3ce7de5f3fdf has failed, removing it from the group.
2026-02-12 18:35:13 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=27] Preparing to rebalance group apicurio-a1c0e1c8-1259-4c5a-bee9-3ce7de5f3fdf in state PreparingRebalance with old generation 1 (reason: removing member apicurio-consumer-ac659e48-56b6-49ee-abb9-d6d7265cd5d5-e7c7b94b-dd7a-430d-91cb-7c60a927ef31 on heartbeat expiration.).
2026-02-12 18:35:13 INFO  [group-coordinator-event-processor-0] GroupMetadataManager:6588 - [GroupCoordinator id=0 topic=__consumer_offsets partition=27] Group apicurio-a1c0e1c8-1259-4c5a-bee9-3ce7de5f3fdf with generation 2 is now empty.
2026-02-12 18:36:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.68 ms each. The slowest event was writeNoOpRecord(1063160392), which took 47.44 ms.
2026-02-12 18:37:01 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:104 - [QuorumController id=0] Periodic task electPreferred generated 0 records in 401 microseconds.
2026-02-12 18:37:01 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:104 - [QuorumController id=0] Periodic task electUnclean generated 0 records in 28 microseconds.
2026-02-12 18:37:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 327 controller events were completed, which took an average of 9.49 ms each. The slowest event was writeNoOpRecord(1894711523), which took 27.75 ms.
2026-02-12 18:38:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.71 ms each. The slowest event was writeNoOpRecord(969574581), which took 61.27 ms.
2026-02-12 18:39:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.59 ms each. The slowest event was writeNoOpRecord(833596689), which took 28.81 ms.
2026-02-12 18:39:46 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:7979 - [GroupCoordinator id=0 topic=__consumer_offsets partition=36] [Group apicurio-991029c8-9382-421f-a678-8cda22726f97] Member apicurio-consumer-5f4d0c29-e6a7-475b-af54-f4b7f69ff415-0a397aeb-ab33-41fa-bf0e-c15416933a95 has left group through explicit `LeaveGroup` request; client reason: consumer poll timeout has expired.
2026-02-12 18:39:46 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6897 - [GroupCoordinator id=0 topic=__consumer_offsets partition=36] Preparing to rebalance group apicurio-991029c8-9382-421f-a678-8cda22726f97 in state PreparingRebalance with old generation 1 (reason: explicit `LeaveGroup` request for (apicurio-consumer-5f4d0c29-e6a7-475b-af54-f4b7f69ff415-0a397aeb-ab33-41fa-bf0e-c15416933a95) members.).
2026-02-12 18:39:46 INFO  [group-coordinator-event-processor-1] GroupMetadataManager:6588 - [GroupCoordinator id=0 topic=__consumer_offsets partition=36] Group apicurio-991029c8-9382-421f-a678-8cda22726f97 with generation 2 is now empty.
2026-02-12 18:40:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 323 controller events were completed, which took an average of 9.59 ms each. The slowest event was writeNoOpRecord(1040072198), which took 65.87 ms.
2026-02-12 18:41:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.59 ms each. The slowest event was writeNoOpRecord(181084230), which took 38.21 ms.
2026-02-12 18:42:01 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:104 - [QuorumController id=0] Periodic task electPreferred generated 0 records in 16 microseconds.
2026-02-12 18:42:01 INFO  [quorum-controller-0-event-handler] PeriodicTaskControlManager:104 - [QuorumController id=0] Periodic task electUnclean generated 0 records in 16 microseconds.
2026-02-12 18:42:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 326 controller events were completed, which took an average of 9.53 ms each. The slowest event was writeNoOpRecord(1995273255), which took 26.78 ms.
2026-02-12 18:42:02 INFO  [controller-0-to-controller-registration-channel-manager] NetworkClient:1072 - [NodeToControllerChannelManager id=0 name=registration] Node 0 disconnected.
2026-02-12 18:43:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 325 controller events were completed, which took an average of 9.74 ms each. The slowest event was writeNoOpRecord(1226845010), which took 42.51 ms.
2026-02-12 18:43:46 INFO  [group-coordinator-event-processor-3] GroupCoordinatorShard:1013 - [GroupCoordinator id=0 topic=__consumer_offsets partition=27] Generated 1 tombstone records while cleaning up group metadata in 1 milliseconds.
2026-02-12 18:43:46 INFO  [group-coordinator-event-processor-3] GroupCoordinatorShard:1013 - [GroupCoordinator id=0 topic=__consumer_offsets partition=8] Generated 1 tombstone records while cleaning up group metadata in 0 milliseconds.
2026-02-12 18:44:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.70 ms each. The slowest event was writeNoOpRecord(1801521078), which took 63.37 ms.
2026-02-12 18:44:01 INFO  [broker-0-to-controller-forwarding-channel-manager] NetworkClient:1072 - [NodeToControllerChannelManager id=0 name=forwarding] Node 0 disconnected.
2026-02-12 18:45:01 INFO  [quorum-controller-0-event-handler] EventPerformanceMonitor:174 - [QuorumController id=0] In the last 60000 ms period, 324 controller events were completed, which took an average of 9.65 ms each. The slowest event was writeNoOpRecord(1077320146), which took 71.05 ms.
